import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import pearsonr, spearmanr, chi2_contingency, normaltest
import nltk
from nltk.corpus import stopwords
import string
from collections import Counter
import time

from reportlab.lib.pagesizes import A4
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.platypus import (
    SimpleDocTemplate,
    Paragraph,
    Spacer,
    Table,
    TableStyle,
    PageBreak,
    Image as RLImage,
)
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from io import BytesIO

# --------------------------- NLTK INIT ---------------------------
try:
    _ = stopwords.words("english")
except LookupError:
    nltk.download("stopwords")

# --------------------------- SESSION STATE ---------------------------
if "dark_mode" not in st.session_state:
    st.session_state["dark_mode"] = False
if "language" not in st.session_state:
    st.session_state["language"] = "EN"

# --------------------------- PAGE CONFIG & CSS ---------------------------
st.set_page_config(page_title="Digital Payment Usage & Financial Discipline Survey", layout="wide")

# Aurora background animation
st.markdown("""
<div class="aurora-container">
    <div class="aurora-layer"></div>
    <div class="aurora-layer"></div>
    <div class="aurora-layer"></div>
</div>
""", unsafe_allow_html=True)

top_col1, top_col2 = st.columns([3, 3])
with top_col1:
    dm = st.toggle("ðŸŒ™ Dark mode", value=st.session_state["dark_mode"])
    st.session_state["dark_mode"] = dm
with top_col2:
    lang = st.radio(
        "Language",
        options=["EN", "ID", "JP", "KR", "CN", "AR"],
        horizontal=True,
        index=["EN", "ID", "JP", "KR", "CN", "AR"].index(st.session_state["language"]),
    )
    st.session_state["language"] = lang

CUSTOM_CSS = """
<style>
body {
    background: #000;
    font-family: "Inter", system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
}
.main-card {
    background-color: rgba(240, 253, 250, 0.94);
    border-radius: 24px;
    padding: 2.0rem 2.4rem;
    box-shadow: 0 18px 45px rgba(15, 23, 42, 0.08);
}
.hero-card {
    background: rgba(255, 255, 255, 0.96);
    border-radius: 14px;
    padding: 2.2rem 2.6rem;
    box-shadow: 0 24px 60px rgba(16, 185, 129, 0.35);
    border: 1px solid rgba(34, 197, 94, 0.35);
}
.upload-card {
    background-color: #FFFFFF;
    border-radius: 24px;
    padding: 1.6rem 2.2rem;
    border: 2px dashed #22c55e;
    text-align: center;
    box-shadow: 0 12px 30px rgba(34, 197, 94, 0.35);
}
.feature-card {
    background-color: #FFFFFF;
    border-radius: 16px;
    padding: 1.3rem 1.5rem;
    box-shadow: 0 12px 28px rgba(16, 185, 129, 0.35);
    border: 1px solid rgba(34, 197, 94, 0.30);
}
.helper-text {
    font-size: 0.82rem;
    color: #047857;
}
.decorative-divider {
    height: 1px;
    width: 100%;
    margin: 0.7rem 0 1.3rem 0;
    background: linear-gradient(to right, transparent, #22c55e, transparent);
}
.summary-badge {
    padding: 0.4rem 0.9rem;
    border-radius: 999px;
    background: rgba(16, 185, 129, 0.08);
    border: 1px solid rgba(16, 185, 129, 0.4);
    font-size: 0.8rem;
    color: #047857;
    display: inline-flex;
    align-items: center;
    gap: 0.4rem;
    margin-right: 0.4rem;
}
.summary-dot {
    width: 8px;
    height: 8px;
    border-radius: 999px;
    background: #22c55e;
}
.section-card {
    background-color: #FFFFFF;
    border-radius: 18px;
    padding: 1.0rem 1.4rem;
    border: 1px solid rgba(34, 197, 94, 0.35);
    box-shadow: 0 10px 26px rgba(16, 185, 129, 0.30);
    margin: 0.6rem 0 0.9rem 0;
}
.section-title {
    font-weight: 700;
    font-size: 1.0rem;
    margin-bottom: 0.25rem;
}
.section-subtitle {
    font-size: 0.85rem;
    color: #047857;
    margin-bottom: 0;
}
.aurora-container {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    z-index: -1;
    overflow: hidden;
}
.aurora-layer {
    position: absolute;
    width: 100%;
    height: 100%;
    background: radial-gradient(ellipse at 50% 50%, rgba(0, 100, 255, 0.3) 0%, transparent 50%);
    animation: wave 15s infinite linear;
}
.aurora-layer:nth-child(2) {
    background: radial-gradient(ellipse at 30% 70%, rgba(255, 100, 0, 0.2) 0%, transparent 50%);
    animation: wave 20s infinite linear 5s;
}
.aurora-layer:nth-child(3) {
    background: radial-gradient(ellipse at 70% 30%, rgba(100, 255, 0, 0.25) 0%, transparent 50%);
    animation: wave 25s infinite linear 10s;
}
@keyframes wave {
    0% {
        transform: scale(1) rotate(0deg) translateX(-20%) translateY(0%);
    }
    25% {
        transform: scale(1.05) rotate(90deg) translateX(0%) translateY(-10%);
    }
    50% {
        transform: scale(1.1) rotate(180deg) translateX(20%) translateY(0%);
    }
    75% {
        transform: scale(1.05) rotate(270deg) translateX(0%) translateY(10%);
    }
    100% {
        transform: scale(1) rotate(360deg) translateX(-20%) translateY(0%);
    }
}
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

if st.session_state["dark_mode"]:
    st.markdown(
        """
        <style>
        body {
            background: radial-gradient(circle at top, #0f172a 0%, #020617 55%, #000000 100%) !important;
            color: #e5e7eb !important;
        }
        .main-card, .hero-card, .upload-card {
            background-color: rgba(15, 23, 42, 0.96) !important;
            color: #e5e7eb !important;
        }
        .helper-text {
            color: #a7f3d0 !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

# --------------------------- MULTI-LANGUAGE TEXTS ---------------------------
TEXTS = {
    "EN": {
        "title": "ðŸ“Š Digital Payment Usage & Financial Discipline Survey",
        "subtitle": "survey data analysis",
        "upload_subheader": "ðŸ“ Upload Survey Data",
        "upload_label": "Drag & drop file here or click to browse (CSV, XLS, XLSX)",
        "data_preview": "Data Preview (up to first 1000 rows)",
        "text_processing_subheader": "ðŸ“ Text Preprocessing",
        "text_columns_detected": "Detected text columns:",
        "select_text_col": "Select a text column to process",
        "no_text_columns": "No text-type columns detected.",
        "text_processing_note": "Text will be lowercased, punctuation removed, tokenized (split by spaces), and English stopwords removed.",
        "sample_tokens": "Sample of processed tokens",
        "top_words": "Top 10 Words by Frequency",
        "stats_subheader": "ðŸ“ˆ Descriptive Statistics & Distribution",
        "select_numeric_col": "Select a numeric column for statistics & plots",
        "no_numeric_cols": "No numeric columns available.",
        "desc_stats": "Descriptive statistics for the selected column",
        "freq_table_subheader": "ðŸ“Š Categorical Frequency Table",
        "select_categorical_col": "Select a categorical column for frequency table",
        "no_categorical_cols": "No categorical columns available.",
        "freq_count": "Count",
        "freq_percent": "Percent (%)",
        "visual_subheader": "ðŸ“‰ Data Visualizations",
        "histogram": "Histogram",
        "boxplot": "Boxplot",
        "correlation_subheader": "ðŸ”— Correlation & Statistical Tests",
        "pearson_header": "Pearson Correlation",
        "spearman_header": "Spearman Rank Correlation",
        "chi_header": "Chi-square Test",
        "select_x_numeric": "Select X variable (numeric)",
        "select_y_numeric": "Select Y variable (numeric)",
        "not_enough_numeric": "Not enough numeric columns for this analysis.",
        "pearson_result": "Pearson Correlation Result",
        "spearman_result": "Spearman Rank Correlation Result",
        "corr_coef": "Correlation coefficient (r)",
        "p_value": "p-value",
        "interpretation": "Interpretation",
        "select_x_cat": "Select X variable (categorical)",
        "select_y_cat": "Select Y variable (categorical)",
        "not_enough_categorical": "Not enough categorical columns for Chi-square test.",
        "chi_square_result": "Chi-square Test Result",
        "chi_square_stat": "Chi-square statistic",
        "chi_square_df": "Degrees of freedom (df)",
        "chi_square_p": "p-value",
        "alpha_note": "Significance tested at Î± = 0.05.",
        "significant_assoc": "There is a statistically significant association between the two variables.",
        "no_significant_assoc": "There is no statistically significant association between the two variables.",
        "corr_direction_positive": "Positive relationship: as X increases, Y tends to increase.",
        "corr_direction_negative": "Negative relationship: as X increases, Y tends to decrease.",
        "corr_direction_zero": "No clear direction of relationship (near zero).",
        "corr_strength_none": "Virtually no relationship.",
        "corr_strength_weak": "Weak relationship.",
        "corr_strength_moderate": "Moderate relationship.",
        "corr_strength_strong": "Strong relationship.",
        "warning_select_valid": "Please select a valid combination of columns.",
        "header_github": "Fork on GitHub",
        "nav_desc": "Descriptive Stats",
        "nav_visual": "Visualizations",
        "nav_corr": "Correlations & Tests",
        "nav_text": "Text Processing",
        "export_title": "Export Report",
        "export_desc": "Generate a complete PDF with all descriptive stats, normality test, histograms, boxplots, correlations, and text analysis summary.",
        "export_button": "Generate PDF report",
        "export_filename": "survey_full_report.pdf",
        "pdf_title": "Survey Data Full Report",
        "pdf_section_numdist": "1. Numeric Variables - Distributions",
        "pdf_section_scatter": "2. Scatter Plots - Relationships",
        "pdf_section_catbar": "3. Categorical Variables - Bar Charts",
        "pdf_section_numfull": "4. Numeric Variables - Full Statistics",
        "pdf_section_catfreq": "5. Categorical Variables - Frequency Tables",
        "pdf_section_corr": "6. Correlation Analysis",
        "pdf_section_text": "7. Text Analysis - Top Words",
        "pdf_notext": "No text data to analyze.",
        "filter_data_optional": "Filter data (optional)",
        "filter_column": "Filter column",
        "no_filter": "(No filter)",
        "select_values": "Select values",
        "summary_normality": "Summary & Normality",
        "distribution": "Distribution",
        "select_column_distribution": "Select column for distribution",
        "normality_test": "Normality test (Dâ€™Agostino-Pearson)",
        "statistic": "Statistic",
        "deviate_normal": "Data deviate significantly from normal distribution (reject H0 at Î± = 0.05).",
        "no_deviate_normal": "No significant deviation from normal distribution (fail to reject H0 at Î± = 0.05).",
        "not_enough_normality": "Not enough data points for normality test (need at least 8 non-missing values).",
        "histogram_boxplot": "Histogram / Boxplot",
        "scatter_bar": "Scatter & Bar",
        "x_variable_numeric": "X variable (numeric)",
        "y_variable_numeric": "Y variable (numeric)",
        "scatter_plot": "Scatter plot",
        "not_enough_scatter": "Not enough valid data for scatter plot.",
        "need_2_numeric": "Need at least 2 numeric columns for scatter plot.",
        "categorical_bar": "Categorical column for bar chart",
        "bar_chart": "Bar chart (top 20)",
        "no_categorical_bar": "No categorical columns for bar chart.",
        "independent_variable": "Independent variable",
        "dependent_variable": "Dependent variable",
        "observed": "Observed",
        "expected": "Expected",
        "no_file": "Please upload a file to get started.",
        "data_preview_subtitle": "survey data analysis",
    },
    "ID": {
        "title": "ðŸ“Š Digital Payment Usage & Financial Discipline Survey",
        "subtitle": "survey data analysis",
        "upload_subheader": "ðŸ“ Unggah Data Survei",
        "upload_label": "Tarik & letakkan file di sini atau klik untuk memilih (CSV, XLS, XLSX)",
        "data_preview": "Pratinjau Data (maksimal 1000 baris pertama)",
        "text_processing_subheader": "ðŸ“ Pemrosesan Teks",
        "text_columns_detected": "Kolom teks terdeteksi:",
        "select_text_col": "Pilih kolom teks untuk diproses",
        "no_text_columns": "Tidak ada kolom bertipe teks.",
        "text_processing_note": "Teks akan di-lowercase, tanda baca dihapus, dipisah per kata, dan stopwords bahasa Inggris dihapus.",
        "sample_tokens": "Contoh token yang telah diproses",
        "top_words": "10 Kata Teratas berdasarkan Frekuensi",
        "stats_subheader": "ðŸ“ˆ Statistik Deskriptif & Distribusi",
        "select_numeric_col": "Pilih kolom numerik untuk statistik & grafik",
        "no_numeric_cols": "Tidak ada kolom numerik.",
        "desc_stats": "Statistik deskriptif untuk kolom yang dipilih",
        "freq_table_subheader": "ðŸ“Š Tabel Frekuensi Kategorikal",
        "select_categorical_col": "Pilih kolom kategorikal untuk tabel frekuensi",
        "no_categorical_cols": "Tidak ada kolom kategorikal.",
        "freq_count": "Frekuensi",
        "freq_percent": "Persentase (%)",
        "visual_subheader": "ðŸ“‰ Visualisasi Data",
        "histogram": "Histogram",
        "boxplot": "Boxplot",
        "correlation_subheader": "ðŸ”— Korelasi & Uji Statistik",
        "pearson_header": "Korelasi Pearson",
        "spearman_header": "Korelasi Spearman",
        "chi_header": "Uji Chi-square",
        "select_x_numeric": "Pilih variabel X (numerik)",
        "select_y_numeric": "Pilih variabel Y (numerik)",
        "not_enough_numeric": "Kolom numerik tidak mencukupi untuk analisis ini.",
        "pearson_result": "Hasil Korelasi Pearson",
        "spearman_result": "Hasil Korelasi Spearman",
        "corr_coef": "Koefisien korelasi (r)",
        "p_value": "p-value",
        "interpretation": "Interpretasi",
        "select_x_cat": "Pilih variabel X (kategorikal)",
        "select_y_cat": "Pilih variabel Y (kategorikal)",
        "not_enough_categorical": "Kolom kategorikal tidak mencukupi untuk uji Chi-square.",
        "chi_square_result": "Hasil Uji Chi-square",
        "chi_square_stat": "Statistik Chi-square",
        "chi_square_df": "Derajat bebas (df)",
        "chi_square_p": "p-value",
        "alpha_note": "Signifikansi diuji pada Î± = 0,05.",
        "significant_assoc": "Terdapat hubungan yang signifikan secara statistik antara kedua variabel.",
        "no_significant_assoc": "Tidak terdapat hubungan yang signifikan secara statistik antara kedua variabel.",
        "corr_direction_positive": "Hubungan positif: ketika X naik, Y cenderung naik.",
        "corr_direction_negative": "Hubungan negatif: ketika X naik, Y cenderung turun.",
        "corr_direction_zero": "Tidak ada arah hubungan yang jelas (mendekati nol).",
        "corr_strength_none": "Hampir tidak ada hubungan.",
        "corr_strength_weak": "Hubungan lemah.",
        "corr_strength_moderate": "Hubungan sedang.",
        "corr_strength_strong": "Hubungan kuat.",
        "warning_select_valid": "Silakan pilih kombinasi kolom yang valid.",
        "header_github": "Fork di GitHub",
        "nav_desc": "Statistik Deskriptif",
        "nav_visual": "Visualisasi",
        "nav_corr": "Korelasi & Uji",
        "nav_text": "Pemrosesan Teks",
        "export_title": "Ekspor Laporan",
        "export_desc": "Buat PDF lengkap berisi statistik deskriptif, uji normalitas, histogram, boxplot, korelasi, dan ringkasan analisis teks.",
        "export_button": "Buat laporan PDF",
        "export_filename": "laporan_survei_lengkap.pdf",
        "pdf_title": "Laporan Lengkap Data Survei",
        "pdf_section_numdist": "1. Variabel Numerik - Distribusi",
        "pdf_section_scatter": "2. Scatter Plot - Hubungan",
        "pdf_section_catbar": "3. Variabel Kategorikal - Diagram Batang",
        "pdf_section_numfull": "4. Variabel Numerik - Statistik Lengkap",
        "pdf_section_catfreq": "5. Variabel Kategorikal - Tabel Frekuensi",
        "pdf_section_corr": "6. Analisis Korelasi",
        "pdf_section_text": "7. Analisis Teks - Kata Teratas",
        "pdf_notext": "Tidak ada data teks untuk dianalisis.",
    },
    "JP": {  # Japanese
        "title": "ðŸ“Š Digital Payment Usage & Financial Discipline Survey",
        "subtitle": "survey data analysis",
        "upload_subheader": "ðŸ“ ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        "upload_label": "ã“ã“ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã€ã¾ãŸã¯ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠžï¼ˆCSV, XLS, XLSXï¼‰",
        "data_preview": "ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­1000è¡Œã¾ã§ï¼‰",
        "text_processing_subheader": "ðŸ“ ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†",
        "text_columns_detected": "æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆåˆ—ï¼š",
        "select_text_col": "å‰å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠž",
        "no_text_columns": "ãƒ†ã‚­ã‚¹ãƒˆåž‹ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
        "text_processing_note": "ãƒ†ã‚­ã‚¹ãƒˆã¯å°æ–‡å­—åŒ–ã•ã‚Œã€å¥èª­ç‚¹ãŒå‰Šé™¤ã•ã‚Œã€ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²ã•ã‚Œã€è‹±èªžã®ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãŒé™¤åŽ»ã•ã‚Œã¾ã™ã€‚",
        "sample_tokens": "å‰å‡¦ç†ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚µãƒ³ãƒ—ãƒ«",
        "top_words": "å‡ºç¾é »åº¦ãƒˆãƒƒãƒ—10ã®å˜èªž",
        "stats_subheader": "ðŸ“ˆ è¨˜è¿°çµ±è¨ˆã¨åˆ†å¸ƒ",
        "select_numeric_col": "çµ±è¨ˆãƒ»ã‚°ãƒ©ãƒ•ç”¨ã®æ•°å€¤åˆ—ã‚’é¸æŠž",
        "no_numeric_cols": "åˆ©ç”¨å¯èƒ½ãªæ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "desc_stats": "é¸æŠžã•ã‚ŒãŸåˆ—ã®è¨˜è¿°çµ±è¨ˆ",
        "freq_table_subheader": "ðŸ“Š ã‚«ãƒ†ã‚´ãƒªé »åº¦è¡¨",
        "select_categorical_col": "é »åº¦è¡¨ã‚’ä½œæˆã™ã‚‹ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’é¸æŠž",
        "no_categorical_cols": "ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "freq_count": "åº¦æ•°",
        "freq_percent": "å‰²åˆï¼ˆï¼…ï¼‰",
        "visual_subheader": "ðŸ“‰ ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–",
        "histogram": "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ",
        "boxplot": "ç®±ã²ã’å›³",
        "correlation_subheader": "ðŸ”— ç›¸é–¢ã¨çµ±è¨ˆçš„æ¤œå®š",
        "pearson_header": "ãƒ”ã‚¢ã‚½ãƒ³ã®ç›¸é–¢",
        "spearman_header": "ã‚¹ãƒ”ã‚¢ãƒžãƒ³ã®é †ä½ç›¸é–¢",
        "chi_header": "ã‚«ã‚¤äºŒä¹—æ¤œå®š",
        "select_x_numeric": "Xå¤‰æ•°ï¼ˆæ•°å€¤ï¼‰ã‚’é¸æŠž",
        "select_y_numeric": "Yå¤‰æ•°ï¼ˆæ•°å€¤ï¼‰ã‚’é¸æŠž",
        "not_enough_numeric": "ã“ã®åˆ†æžã«å¿…è¦ãªæ•°å€¤åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚",
        "pearson_result": "ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ã®çµæžœ",
        "spearman_result": "ã‚¹ãƒ”ã‚¢ãƒžãƒ³ç›¸é–¢ã®çµæžœ",
        "corr_coef": "ç›¸é–¢ä¿‚æ•° (r)",
        "p_value": "på€¤",
        "interpretation": "è§£é‡ˆ",
        "select_x_cat": "Xå¤‰æ•°ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰ã‚’é¸æŠž",
        "select_y_cat": "Yå¤‰æ•°ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰ã‚’é¸æŠž",
        "not_enough_categorical": "ã‚«ã‚¤äºŒä¹—æ¤œå®šã«å¿…è¦ãªã‚«ãƒ†ã‚´ãƒªåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚",
        "chi_square_result": "ã‚«ã‚¤äºŒä¹—æ¤œå®šã®çµæžœ",
        "chi_square_stat": "ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡",
        "chi_square_df": "è‡ªç”±åº¦ (df)",
        "chi_square_p": "på€¤",
        "alpha_note": "æœ‰æ„æ°´æº– Î± = 0.05 ã§æ¤œå®šã—ã¦ã„ã¾ã™ã€‚",
        "significant_assoc": "2ã¤ã®å¤‰æ•°ã®é–“ã«çµ±è¨ˆçš„ã«æœ‰æ„ãªé–¢ä¿‚ãŒã‚ã‚Šã¾ã™ã€‚",
        "no_significant_assoc": "2ã¤ã®å¤‰æ•°ã®é–“ã«çµ±è¨ˆçš„ã«æœ‰æ„ãªé–¢ä¿‚ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        "corr_direction_positive": "æ­£ã®é–¢ä¿‚ï¼šXãŒå¢—åŠ ã™ã‚‹ã¨Yã‚‚å¢—åŠ ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚",
        "corr_direction_negative": "è² ã®é–¢ä¿‚ï¼šXãŒå¢—åŠ ã™ã‚‹ã¨Yã¯æ¸›å°‘ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚",
        "corr_direction_zero": "æ˜Žç¢ºãªé–¢ä¿‚ã®æ–¹å‘ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã»ã¼0ï¼‰ã€‚",
        "corr_strength_none": "ã»ã¨ã‚“ã©é–¢ä¿‚ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
        "corr_strength_weak": "å¼±ã„é–¢ä¿‚ã§ã™ã€‚",
        "corr_strength_moderate": "ä¸­ç¨‹åº¦ã®é–¢ä¿‚ã§ã™ã€‚",
        "corr_strength_strong": "å¼·ã„é–¢ä¿‚ã§ã™ã€‚",
        "warning_select_valid": "æœ‰åŠ¹ãªåˆ—ã®çµ„ã¿åˆã‚ã›ã‚’é¸æŠžã—ã¦ãã ã•ã„ã€‚",
        "header_github": "GitHubã§ãƒ•ã‚©ãƒ¼ã‚¯",
        "nav_desc": "è¨˜è¿°çµ±è¨ˆ",
        "nav_visual": "å¯è¦–åŒ–",
        "nav_corr": "ç›¸é–¢ãƒ»æ¤œå®š",
        "nav_text": "ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†",
        "export_title": "ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
        "export_desc": "è¨˜è¿°çµ±è¨ˆãƒ»æ­£è¦æ€§æ¤œå®šãƒ»ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãƒ»ç®±ã²ã’å›³ãƒ»ç›¸é–¢ãƒ»ãƒ†ã‚­ã‚¹ãƒˆåˆ†æžã‚µãƒžãƒªãƒ¼ã‚’å«ã‚€PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚",
        "export_button": "PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ",
        "export_filename": "survey_full_report_jp.pdf",
        "pdf_title": "ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆ",
        "pdf_section_numdist": "1. æ•°å€¤å¤‰æ•° - åˆ†å¸ƒ",
        "pdf_section_scatter": "2. æ•£å¸ƒå›³ - é–¢ä¿‚",
        "pdf_section_catbar": "3. ã‚«ãƒ†ã‚´ãƒªå¤‰æ•° - æ£’ã‚°ãƒ©ãƒ•",
        "pdf_section_numfull": "4. æ•°å€¤å¤‰æ•° - è©³ç´°çµ±è¨ˆ",
        "pdf_section_catfreq": "5. ã‚«ãƒ†ã‚´ãƒªå¤‰æ•° - åº¦æ•°è¡¨",
        "pdf_section_corr": "6. ç›¸é–¢åˆ†æž",
        "pdf_section_text": "7. ãƒ†ã‚­ã‚¹ãƒˆåˆ†æž - ä¸Šä½èªž",
        "pdf_notext": "åˆ†æžã§ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
    },
    "KR": {  # Korean
        "title": "ðŸ“Š Digital Payment Usage & Financial Discipline Survey",
        "subtitle": "survey data analysis",
        "upload_subheader": "ðŸ“ ì„¤ë¬¸ ë°ì´í„° ì—…ë¡œë“œ",
        "upload_label": "ì—¬ê¸°ì— íŒŒì¼ì„ ë“œëž˜ê·¸ ì•¤ ë“œë¡­í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš” (CSV, XLS, XLSX)",
        "data_preview": "ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ ì²« 1000í–‰)",
        "text_processing_subheader": "ðŸ“ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬",
        "text_columns_detected": "ê°ì§€ëœ í…ìŠ¤íŠ¸ ì—´:",
        "select_text_col": "ì „ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ì—´ ì„ íƒ",
        "no_text_columns": "í…ìŠ¤íŠ¸ í˜•ì‹ì˜ ì—´ì´ ì—†ìŠµë‹ˆë‹¤.",
        "text_processing_note": "í…ìŠ¤íŠ¸ëŠ” ì†Œë¬¸ìžë¡œ ë³€í™˜ë˜ê³ , êµ¬ë‘ì ì´ ì œê±°ë˜ë©°, ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë¶„í• ë˜ê³ , ì˜ì–´ ë¶ˆìš©ì–´ê°€ ì œê±°ë©ë‹ˆë‹¤.",
        "sample_tokens": "ì „ì²˜ë¦¬ëœ í† í° ìƒ˜í”Œ",
        "top_words": "ì¶œí˜„ ë¹ˆë„ ìƒìœ„ 10ê°œ ë‹¨ì–´",
        "stats_subheader": "ðŸ“ˆ ê¸°ìˆ í†µê³„ ë° ë¶„í¬",
        "select_numeric_col": "í†µê³„/ê·¸ëž˜í”„ìš© ìˆ«ìž ì—´ ì„ íƒ",
        "no_numeric_cols": "ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ«ìž ì—´ì´ ì—†ìŠµë‹ˆë‹¤.",
        "desc_stats": "ì„ íƒí•œ ì—´ì˜ ê¸°ìˆ í†µê³„",
        "freq_table_subheader": "ðŸ“Š ë²”ì£¼í˜• ë¹ˆë„í‘œ",
        "select_categorical_col": "ë¹ˆë„í‘œë¥¼ ë§Œë“¤ ë²”ì£¼í˜• ì—´ ì„ íƒ",
        "no_categorical_cols": "ë²”ì£¼í˜• ì—´ì´ ì—†ìŠµë‹ˆë‹¤.",
        "freq_count": "ë¹ˆë„",
        "freq_percent": "ë¹„ìœ¨(%)",
        "visual_subheader": "ðŸ“‰ ë°ì´í„° ì‹œê°í™”",
        "histogram": "ížˆìŠ¤í† ê·¸ëž¨",
        "boxplot": "ë°•ìŠ¤í”Œë¡¯",
        "correlation_subheader": "ðŸ”— ìƒê´€ê´€ê³„ ë° í†µê³„ ê²€ì •",
        "pearson_header": "í”¼ì–´ìŠ¨ ìƒê´€",
        "spearman_header": "ìŠ¤í”¼ì–´ë§Œ ìˆœìœ„ ìƒê´€",
        "chi_header": "ì¹´ì´ì œê³± ê²€ì •",
        "select_x_numeric": "X ë³€ìˆ˜(ìˆ«ìž)ë¥¼ ì„ íƒ",
        "select_y_numeric": "Y ë³€ìˆ˜(ìˆ«ìž)ë¥¼ ì„ íƒ",
        "not_enough_numeric": "ì´ ë¶„ì„ì— í•„ìš”í•œ ìˆ«ìž ì—´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.",
        "pearson_result": "í”¼ì–´ìŠ¨ ìƒê´€ ê²°ê³¼",
        "spearman_result": "ìŠ¤í”¼ì–´ë§Œ ìƒê´€ ê²°ê³¼",
        "corr_coef": "ìƒê´€ê³„ìˆ˜ (r)",
        "p_value": "p-ê°’",
        "interpretation": "í•´ì„",
        "select_x_cat": "X ë³€ìˆ˜(ë²”ì£¼í˜•)ë¥¼ ì„ íƒ",
        "select_y_cat": "Y ë³€ìˆ˜(ë²”ì£¼í˜•)ë¥¼ ì„ íƒ",
        "not_enough_categorical": "ì¹´ì´ì œê³± ê²€ì •ì— í•„ìš”í•œ ë²”ì£¼í˜• ì—´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.",
        "chi_square_result": "ì¹´ì´ì œê³± ê²€ì • ê²°ê³¼",
        "chi_square_stat": "ì¹´ì´ì œê³± í†µê³„ëŸ‰",
        "chi_square_df": "ìžìœ ë„ (df)",
        "chi_square_p": "p-ê°’",
        "alpha_note": "ìœ ì˜ìˆ˜ì¤€ Î± = 0.05ì—ì„œ ê²€ì •í•©ë‹ˆë‹¤.",
        "significant_assoc": "ë‘ ë³€ìˆ˜ ì‚¬ì´ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê´€ê³„ê°€ ìžˆìŠµë‹ˆë‹¤.",
        "no_significant_assoc": "ë‘ ë³€ìˆ˜ ì‚¬ì´ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.",
        "corr_direction_positive": "ì–‘ì˜ ê´€ê³„: Xê°€ ì¦ê°€í•˜ë©´ Yë„ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìžˆìŠµë‹ˆë‹¤.",
        "corr_direction_negative": "ìŒì˜ ê´€ê³„: Xê°€ ì¦ê°€í•˜ë©´ YëŠ” ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ìžˆìŠµë‹ˆë‹¤.",
        "corr_direction_zero": "ëª…í™•í•œ ê´€ê³„ ë°©í–¥ì´ ì—†ìŠµë‹ˆë‹¤(ê±°ì˜ 0).",
        "corr_strength_none": "ê±°ì˜ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.",
        "corr_strength_weak": "ì•½í•œ ê´€ê³„ìž…ë‹ˆë‹¤.",
        "corr_strength_moderate": "ë³´í†µ ì •ë„ì˜ ê´€ê³„ìž…ë‹ˆë‹¤.",
        "corr_strength_strong": "ê°•í•œ ê´€ê³„ìž…ë‹ˆë‹¤.",
        "warning_select_valid": "ì˜¬ë°”ë¥¸ ì—´ ì¡°í•©ì„ ì„ íƒí•˜ì„¸ìš”.",
        "header_github": "GitHubì—ì„œ í¬í¬",
        "nav_desc": "ê¸°ìˆ í†µê³„",
        "nav_visual": "ì‹œê°í™”",
        "nav_corr": "ìƒê´€ ë° ê²€ì •",
        "nav_text": "í…ìŠ¤íŠ¸ ì²˜ë¦¬",
        "export_title": "ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°",
        "export_desc": "ê¸°ìˆ í†µê³„, ì •ê·œì„± ê²€ì •, ížˆìŠ¤í† ê·¸ëž¨, ë°•ìŠ¤í”Œë¡¯, ìƒê´€ë¶„ì„, í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì•½ì„ í¬í•¨í•œ ì „ì²´ PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.",
        "export_button": "PDF ë³´ê³ ì„œ ìƒì„±",
        "export_filename": "survey_full_report_kr.pdf",
        "pdf_title": "ì„¤ë¬¸ ë°ì´í„° ì „ì²´ ë³´ê³ ì„œ",
        "pdf_section_numdist": "1. ìˆ˜ì¹˜ ë³€ìˆ˜ - ë¶„í¬",
        "pdf_section_scatter": "2. ì‚°ì ë„ - ê´€ê³„",
        "pdf_section_catbar": "3. ë²”ì£¼í˜• ë³€ìˆ˜ - ë§‰ëŒ€ ê·¸ëž˜í”„",
        "pdf_section_numfull": "4. ìˆ˜ì¹˜ ë³€ìˆ˜ - ìƒì„¸ í†µê³„",
        "pdf_section_catfreq": "5. ë²”ì£¼í˜• ë³€ìˆ˜ - ë„ìˆ˜í‘œ",
        "pdf_section_corr": "6. ìƒê´€ ë¶„ì„",
        "pdf_section_text": "7. í…ìŠ¤íŠ¸ ë¶„ì„ - ìƒìœ„ ë‹¨ì–´",
        "pdf_notext": "ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
    },
    "CN": {  # Chinese (Simplified)
        "title": "ðŸ“Š Digital Payment Usage & Financial Discipline Survey",
        "subtitle": "survey data analysis",
        "upload_subheader": "ðŸ“ ä¸Šä¼ é—®å·æ•°æ®",
        "upload_label": "å°†æ–‡ä»¶æ‹–æ”¾åˆ°æ­¤å¤„æˆ–ç‚¹å‡»é€‰æ‹©ï¼ˆCSV, XLS, XLSXï¼‰",
        "data_preview": "æ•°æ®é¢„è§ˆï¼ˆå‰ 1000 è¡Œï¼‰",
        "text_processing_subheader": "ðŸ“ æ–‡æœ¬é¢„å¤„ç†",
        "text_columns_detected": "æ£€æµ‹åˆ°çš„æ–‡æœ¬åˆ—ï¼š",
        "select_text_col": "é€‰æ‹©è¦å¤„ç†çš„æ–‡æœ¬åˆ—",
        "no_text_columns": "æœªæ‰¾åˆ°æ–‡æœ¬ç±»åž‹çš„åˆ—ã€‚",
        "text_processing_note": "æ–‡æœ¬å°†è¢«è½¬ä¸ºå°å†™ï¼ŒåŽ»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä»¥ç©ºæ ¼åˆ†è¯ï¼Œå¹¶ç§»é™¤è‹±æ–‡åœç”¨è¯ã€‚",
        "sample_tokens": "é¢„å¤„ç†åŽçš„è¯å…ƒç¤ºä¾‹",
        "top_words": "è¯é¢‘æœ€é«˜çš„ 10 ä¸ªè¯",
        "stats_subheader": "ðŸ“ˆ æè¿°æ€§ç»Ÿè®¡ä¸Žåˆ†å¸ƒ",
        "select_numeric_col": "é€‰æ‹©ç”¨äºŽç»Ÿè®¡/ç»˜å›¾çš„æ•°å€¼åˆ—",
        "no_numeric_cols": "æ²¡æœ‰å¯ç”¨çš„æ•°å€¼åˆ—ã€‚",
        "desc_stats": "æ‰€é€‰åˆ—çš„æè¿°æ€§ç»Ÿè®¡",
        "freq_table_subheader": "ðŸ“Š åˆ†ç±»é¢‘æ•°è¡¨",
        "select_categorical_col": "é€‰æ‹©ç”¨äºŽé¢‘æ•°è¡¨çš„åˆ†ç±»åˆ—",
        "no_categorical_cols": "æ²¡æœ‰åˆ†ç±»åˆ—ã€‚",
        "freq_count": "é¢‘æ•°",
        "freq_percent": "ç™¾åˆ†æ¯”ï¼ˆ%ï¼‰",
        "visual_subheader": "ðŸ“‰ æ•°æ®å¯è§†åŒ–",
        "histogram": "ç›´æ–¹å›¾",
        "boxplot": "ç®±çº¿å›¾",
        "correlation_subheader": "ðŸ”— ç›¸å…³æ€§ä¸Žç»Ÿè®¡æ£€éªŒ",
        "pearson_header": "çš®å°”é€Šç›¸å…³",
        "spearman_header": "æ–¯çš®å°”æ›¼ç­‰çº§ç›¸å…³",
        "chi_header": "å¡æ–¹æ£€éªŒ",
        "select_x_numeric": "é€‰æ‹© X å˜é‡ï¼ˆæ•°å€¼ï¼‰",
        "select_y_numeric": "é€‰æ‹© Y å˜é‡ï¼ˆæ•°å€¼ï¼‰",
        "not_enough_numeric": "å¯ç”¨äºŽè¯¥åˆ†æžçš„æ•°å€¼åˆ—ä¸è¶³ã€‚",
        "pearson_result": "çš®å°”é€Šç›¸å…³ç»“æžœ",
        "spearman_result": "æ–¯çš®å°”æ›¼ç›¸å…³ç»“æžœ",
        "corr_coef": "ç›¸å…³ç³»æ•° (r)",
        "p_value": "p å€¼",
        "interpretation": "è§£é‡Š",
        "select_x_cat": "é€‰æ‹© X å˜é‡ï¼ˆåˆ†ç±»ï¼‰",
        "select_y_cat": "é€‰æ‹© Y å˜é‡ï¼ˆåˆ†ç±»ï¼‰",
        "not_enough_categorical": "ç”¨äºŽå¡æ–¹æ£€éªŒçš„åˆ†ç±»åˆ—ä¸è¶³ã€‚",
        "chi_square_result": "å¡æ–¹æ£€éªŒç»“æžœ",
        "chi_square_stat": "å¡æ–¹ç»Ÿè®¡é‡",
        "chi_square_df": "è‡ªç”±åº¦ (df)",
        "chi_square_p": "p å€¼",
        "alpha_note": "åœ¨æ˜¾è‘—æ€§æ°´å¹³ Î± = 0.05 ä¸‹è¿›è¡Œæ£€éªŒã€‚",
        "significant_assoc": "ä¸¤ä¸ªå˜é‡ä¹‹é—´å­˜åœ¨ç»Ÿè®¡ä¸Šæ˜¾è‘—çš„å…³è”ã€‚",
        "no_significant_assoc": "ä¸¤ä¸ªå˜é‡ä¹‹é—´ä¸å­˜åœ¨ç»Ÿè®¡ä¸Šæ˜¾è‘—çš„å…³è”ã€‚",
        "corr_direction_positive": "æ­£ç›¸å…³ï¼šX å¢žåŠ æ—¶ï¼ŒY é€šå¸¸ä¹Ÿå¢žåŠ ã€‚",
        "corr_direction_negative": "è´Ÿç›¸å…³ï¼šX å¢žåŠ æ—¶ï¼ŒY é€šå¸¸å‡å°‘ã€‚",
        "corr_direction_zero": "æ²¡æœ‰æ˜Žæ˜¾çš„ç›¸å…³æ–¹å‘ï¼ˆæŽ¥è¿‘ 0ï¼‰ã€‚",
        "corr_strength_none": "å‡ ä¹Žæ²¡æœ‰ç›¸å…³å…³ç³»ã€‚",
        "corr_strength_weak": "ç›¸å…³å…³ç³»è¾ƒå¼±ã€‚",
        "corr_strength_moderate": "ç›¸å…³å…³ç³»ä¸­ç­‰ã€‚",
        "corr_strength_strong": "ç›¸å…³å…³ç³»è¾ƒå¼ºã€‚",
        "warning_select_valid": "è¯·é€‰æ‹©æœ‰æ•ˆçš„åˆ—ç»„åˆã€‚",
        "header_github": "åœ¨ GitHub ä¸Š Fork",
        "nav_desc": "æè¿°æ€§ç»Ÿè®¡",
        "nav_visual": "å¯è§†åŒ–",
        "nav_corr": "ç›¸å…³ä¸Žæ£€éªŒ",
        "nav_text": "æ–‡æœ¬å¤„ç†",
        "export_title": "å¯¼å‡ºæŠ¥å‘Š",
        "export_desc": "ç”ŸæˆåŒ…å«æè¿°æ€§ç»Ÿè®¡ã€æ­£æ€æ€§æ£€éªŒã€ç›´æ–¹å›¾ã€ç®±çº¿å›¾ã€ç›¸å…³åˆ†æžå’Œæ–‡æœ¬åˆ†æžæ‘˜è¦çš„å®Œæ•´ PDF æŠ¥å‘Šã€‚",
        "export_button": "ç”Ÿæˆ PDF æŠ¥å‘Š",
        "export_filename": "survey_full_report_cn.pdf",
        "pdf_title": "é—®å·æ•°æ®å®Œæ•´æŠ¥å‘Š",
        "pdf_section_numdist": "1. æ•°å€¼å˜é‡ - åˆ†å¸ƒ",
        "pdf_section_scatter": "2. æ•£ç‚¹å›¾ - å…³ç³»",
        "pdf_section_catbar": "3. ç±»åˆ«å˜é‡ - æ¡å½¢å›¾",
        "pdf_section_numfull": "4. æ•°å€¼å˜é‡ - è¯¦ç»†ç»Ÿè®¡",
        "pdf_section_catfreq": "5. ç±»åˆ«å˜é‡ - é¢‘æ•°è¡¨",
        "pdf_section_corr": "6. ç›¸å…³åˆ†æž",
        "pdf_section_text": "7. æ–‡æœ¬åˆ†æž - é«˜é¢‘è¯",
        "pdf_notext": "æ²¡æœ‰å¯ä¾›åˆ†æžçš„æ–‡æœ¬æ•°æ®ã€‚",
    },
    "AR": {  # Arabic
        "title": "ðŸ“Š Digital Payment Usage & Financial Discipline Survey",
        "subtitle": "survey data analysis",
        "upload_subheader": "ðŸ“ Ø±ÙØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù†",
        "upload_label": "Ø§Ø³Ø­Ø¨ ÙˆØ£ÙÙ„Øª Ø§Ù„Ù…Ù„Ù Ù‡Ù†Ø§ Ø£Ùˆ Ø§Ø¶ØºØ· Ù„Ù„Ø§Ø®ØªÙŠØ§Ø± (CSV, XLS, XLSX)",
        "data_preview": "Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø­ØªÙ‰ Ø£ÙˆÙ„ 1000 ØµÙ)",
        "text_processing_subheader": "ðŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ",
        "text_columns_detected": "Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©:",
        "select_text_col": "Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Øµ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
        "no_text_columns": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ù†ÙˆØ¹ Ù†ØµÙŠ.",
        "text_processing_note": "Ø³ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø©ØŒ ÙˆØ¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…ØŒ ÙˆØªÙ‚Ø³ÙŠÙ…Ù‡ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§ØªØŒ ÙˆØ­Ø°Ù ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.",
        "sample_tokens": "Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
        "top_words": "Ø£ÙƒØ«Ø± 10 ÙƒÙ„Ù…Ø§Øª ØªÙƒØ±Ø§Ø±Ø§Ù‹",
        "stats_subheader": "ðŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© ÙˆØ§Ù„ØªÙˆØ²ÙŠØ¹",
        "select_numeric_col": "Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯Ø§Ù‹ Ø±Ù‚Ù…ÙŠØ§Ù‹ Ù„Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª ÙˆØ§Ù„Ø±Ø³ÙˆÙ…",
        "no_numeric_cols": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù…ØªØ§Ø­Ø©.",
        "desc_stats": "Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø­Ø¯Ø¯",
        "freq_table_subheader": "ðŸ“Š Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø± Ù„Ù„ÙØ¦Ø§Øª",
        "select_categorical_col": "Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯Ø§Ù‹ ÙØ¦ÙˆÙŠØ§Ù‹ Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±",
        "no_categorical_cols": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙØ¦ÙˆÙŠØ©.",
        "freq_count": "Ø§Ù„Ø¹Ø¯Ø¯",
        "freq_percent": "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)",
        "visual_subheader": "ðŸ“‰ Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙŠØ§Ù†ÙŠØ§Ù‹",
        "histogram": "Ù…Ø®Ø·Ø· Ø§Ù„ØªÙˆØ²ÙŠØ¹ (Histogram)",
        "boxplot": "Ù…Ø®Ø·Ø· Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ (Boxplot)",
        "correlation_subheader": "ðŸ”— Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©",
        "pearson_header": "Ù…Ø¹Ø§Ù…Ù„ Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠØ±Ø³ÙˆÙ†",
        "spearman_header": "Ù…Ø¹Ø§Ù…Ù„ Ø§Ø±ØªØ¨Ø§Ø· Ø³Ø¨ÙŠØ±Ù…Ø§Ù†",
        "chi_header": "Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§ÙŠ ØªØ±Ø¨ÙŠØ¹",
        "select_x_numeric": "Ø§Ø®ØªØ± Ù…ØªØºÙŠØ± X (Ø±Ù‚Ù…ÙŠ)",
        "select_y_numeric": "Ø§Ø®ØªØ± Ù…ØªØºÙŠØ± Y (Ø±Ù‚Ù…ÙŠ)",
        "not_enough_numeric": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ø¯Ø¯ ÙƒØ§ÙÙ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„.",
        "pearson_result": "Ù†ØªÙŠØ¬Ø© Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠØ±Ø³ÙˆÙ†",
        "spearman_result": "Ù†ØªÙŠØ¬Ø© Ø§Ø±ØªØ¨Ø§Ø· Ø³Ø¨ÙŠØ±Ù…Ø§Ù†",
        "corr_coef": "Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· (r)",
        "p_value": "Ù‚ÙŠÙ…Ø© p",
        "interpretation": "Ø§Ù„ØªÙØ³ÙŠØ±",
        "select_x_cat": "Ø§Ø®ØªØ± Ù…ØªØºÙŠØ± X (ÙØ¦ÙˆÙŠ)",
        "select_y_cat": "Ø§Ø®ØªØ± Ù…ØªØºÙŠØ± Y (ÙØ¦ÙˆÙŠ)",
        "not_enough_categorical": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ø¯Ø¯ ÙƒØ§ÙÙ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§ÙŠ ØªØ±Ø¨ÙŠØ¹.",
        "chi_square_result": "Ù†ØªÙŠØ¬Ø© Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§ÙŠ ØªØ±Ø¨ÙŠØ¹",
        "chi_square_stat": "Ø¥Ø­ØµØ§Ø¦ÙŠØ© ÙƒØ§ÙŠ ØªØ±Ø¨ÙŠØ¹",
        "chi_square_df": "Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±ÙŠØ© (df)",
        "chi_square_p": "Ù‚ÙŠÙ…Ø© p",
        "alpha_note": "ØªÙ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù†Ø¯ Ù…Ø³ØªÙˆÙ‰ Ø¯Ù„Ø§Ù„Ø© Î± = 0.05.",
        "significant_assoc": "Ù‡Ù†Ø§Ùƒ Ø¹Ù„Ø§Ù‚Ø© Ø°Ø§Øª Ø¯Ù„Ø§Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±ÙŠÙ†.",
        "no_significant_assoc": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù‚Ø© Ø°Ø§Øª Ø¯Ù„Ø§Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±ÙŠÙ†.",
        "corr_direction_positive": "Ø¹Ù„Ø§Ù‚Ø© Ø·Ø±Ø¯ÙŠØ©: Ø¹Ù†Ø¯ Ø²ÙŠØ§Ø¯Ø© X ÙŠÙ…ÙŠÙ„ Y Ø¥Ù„Ù‰ Ø§Ù„Ø²ÙŠØ§Ø¯Ø©.",
        "corr_direction_negative": "Ø¹Ù„Ø§Ù‚Ø© Ø¹ÙƒØ³ÙŠØ©: Ø¹Ù†Ø¯ Ø²ÙŠØ§Ø¯Ø© X ÙŠÙ…ÙŠÙ„ Y Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù‚ØµØ§Ù†.",
        "corr_direction_zero": "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØ¬Ø§Ù‡ ÙˆØ§Ø¶Ø­ Ù„Ù„Ø¹Ù„Ø§Ù‚Ø© (Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ø§Ù„ØµÙØ±).",
        "corr_strength_none": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù‚Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹.",
        "corr_strength_weak": "Ø¹Ù„Ø§Ù‚Ø© Ø¶Ø¹ÙŠÙØ©.",
        "corr_strength_moderate": "Ø¹Ù„Ø§Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©.",
        "corr_strength_strong": "Ø¹Ù„Ø§Ù‚Ø© Ù‚ÙˆÙŠØ©.",
        "warning_select_valid": "ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ø¹Ù…Ø¯Ø© ØµØ­ÙŠØ­Ø©.",
        "header_github": "Fork Ø¹Ù„Ù‰ GitHub",
        "nav_desc": "Ø¥Ø­ØµØ§Ø¡Ø§Øª ÙˆØµÙÙŠØ©",
        "nav_visual": "Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©",
        "nav_corr": "Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª",
        "nav_text": "Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ",
        "export_title": "ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±",
        "export_desc": "Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± PDF ÙƒØ§Ù…Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©ØŒ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØŒ ÙˆØ§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©ØŒ ÙˆØ§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§ØªØŒ ÙˆÙ…Ù„Ø®Øµ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ.",
        "export_button": "Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± PDF",
        "export_filename": "survey_full_report_ar.pdf",
        "pdf_title": "ØªÙ‚Ø±ÙŠØ± ÙƒØ§Ù…Ù„ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù†",
        "pdf_section_numdist": "Ù¡. Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ© - Ø§Ù„ØªÙˆØ²ÙŠØ¹",
        "pdf_section_scatter": "Ù¢. Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± - Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª",
        "pdf_section_catbar": "Ù£. Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ© - Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø´Ø±ÙŠØ·ÙŠØ©",
        "pdf_section_numfull": "Ù¤. Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ© - Ø§Ù„Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø©",
        "pdf_section_catfreq": "Ù¥. Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ© - Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±",
        "pdf_section_corr": "Ù¦. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·",
        "pdf_section_text": "Ù§. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ - Ø£Ù‡Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª",
        "pdf_notext": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù†ØµÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„.",
    },
}

def get_text(key: str) -> str:
    lang = st.session_state.get("language", "EN")
    lang_dict = TEXTS.get(lang, TEXTS.get("EN", {}))
    return lang_dict.get(key, key)

# --------------------------- HELPER FUNCTIONS ---------------------------
def load_data(uploaded_file):
    if uploaded_file is None:
        return None
    name = uploaded_file.name.lower()
    try:
        if name.endswith(".csv"):
            return pd.read_csv(uploaded_file)
        if name.endswith(".xls") or name.endswith(".xlsx"):
            return pd.read_excel(uploaded_file)
    except Exception:
        return None
    return None

def preprocess_text_series(series: pd.Series) -> pd.Series:
    eng_stop = set(stopwords.words("english"))
    punct_table = str.maketrans("", "", string.punctuation)

    def _clean(text):
        if pd.isna(text):
            return []
        text = str(text).lower()
        text = text.translate(punct_table)
        tokens = text.split()
        tokens = [t for t in tokens if t.isalpha() and t not in eng_stop]
        return tokens

    return series.apply(_clean)

def descriptive_stats(series: pd.Series) -> pd.DataFrame:
    s = pd.to_numeric(series, errors="coerce")
    stats_dict = {
        "mean": s.mean(),
        "median": s.median(),
        "mode": s.mode().iloc[0] if not s.mode().empty else np.nan,
        "min": s.min(),
        "max": s.max(),
        "std": s.std(),
    }
    return pd.DataFrame(stats_dict, index=[0]).T.rename(columns={0: "value"})

def frequency_tables(series: pd.Series) -> pd.DataFrame:
    freq = series.value_counts(dropna=False)
    pct = series.value_counts(normalize=True, dropna=False) * 100
    return pd.DataFrame({"count": freq, "percent": pct})

def visualize_data(df: pd.DataFrame, col: str):
    s = pd.to_numeric(df[col], errors="coerce").dropna()
    if s.empty:
        st.warning(get_text("warning_select_valid"))
        return
    with st.spinner("Generating visualizations..."):
        time.sleep(0.5)
        c1, c2 = st.columns(2)
        with c1:
            fig, ax = plt.subplots(figsize=(5, 3))
            sns.histplot(s, kde=True, ax=ax, color="#16a34a")
            ax.set_title(get_text("histogram"))
            st.pyplot(fig)
        with c2:
            fig2, ax2 = plt.subplots(figsize=(5, 3))
            sns.boxplot(x=s, ax=ax2, color="#22c55e")
            ax2.set_title(get_text("boxplot"))
            st.pyplot(fig2)

def interpret_strength(r: float) -> str:
    if r is None or np.isnan(r):
        return get_text("corr_strength_none")
    abs_r = abs(r)
    if abs_r < 0.1:
        strength = get_text("corr_strength_none")
    elif abs_r < 0.3:
        strength = get_text("corr_strength_weak")
    elif abs_r < 0.5:
        strength = get_text("corr_strength_moderate")
    else:
        strength = get_text("corr_strength_strong")
    if r > 0:
        direction = get_text("corr_direction_positive")
    elif r < 0:
        direction = get_text("corr_direction_negative")
    else:
        direction = get_text("corr_direction_zero")
    return f"{strength} {direction}"

def correlation_analysis(df: pd.DataFrame, x_col: str, y_col: str, method: str = "pearson"):
    x = pd.to_numeric(df[x_col], errors="coerce")
    y = pd.to_numeric(df[y_col], errors="coerce")
    mask = x.notna() & y.notna()
    x_clean, y_clean = x[mask], y[mask]
    if len(x_clean) < 2:
        return np.nan, np.nan
    if method == "spearman":
        r, p = spearmanr(x_clean, y_clean)
    else:
        r, p = pearsonr(x_clean, y_clean)
    return r, p

def chi_square_test(df: pd.DataFrame, x_col: str, y_col: str):
    table = pd.crosstab(df[x_col], df[y_col])
    if table.size == 0:
        return None, None, None, None
    chi2, p, dof, expected = chi2_contingency(table)
    expected_df = pd.DataFrame(expected, index=table.index, columns=table.columns)
    return chi2, p, dof, expected_df

# --------------------------- PDF REPORT FULL ---------------------------
def build_survey_report_pdf(df, numeric_cols, cat_cols, text_cols):
    buffer = BytesIO()
    doc = SimpleDocTemplate(
        buffer,
        pagesize=A4,
        leftMargin=0.5 * inch,
        rightMargin=0.5 * inch,
        topMargin=0.5 * inch,
        bottomMargin=0.5 * inch,
    )

    story = []

    styles = getSampleStyleSheet()
    GREEN = colors.HexColor("#10B981")

    title_style = ParagraphStyle(
        "Title",
        parent=styles["Heading1"],
        fontName="Helvetica-Bold",
        fontSize=18,
        textColor=GREEN,
        alignment=1,
        spaceAfter=12,
        spaceBefore=6,
    )
    h2_style = ParagraphStyle(
        "Heading2",
        parent=styles["Heading2"],
        fontName="Helvetica-Bold",
        fontSize=14,
        textColor=GREEN,
        spaceBefore=10,
        spaceAfter=6,
    )
    h3_style = ParagraphStyle(
        "Heading3",
        parent=styles["Heading3"],
        fontName="Helvetica-Bold",
        fontSize=11,
        textColor=colors.black,
        spaceBefore=6,
        spaceAfter=4,
    )
    normal_style = ParagraphStyle(
        "NormalCustom",
        parent=styles["BodyText"],
        fontName="Helvetica",
        fontSize=10,
        leading=12,
        spaceAfter=4,
    )
    small_style = ParagraphStyle(
        "Small",
        parent=styles["BodyText"],
        fontName="Helvetica",
        fontSize=8,
        leading=9.5,
        spaceAfter=2,
    )

    def make_table(data, col_widths=None, font_size=8, header_bg=GREEN):
        if not data:
            return None
        tbl = Table(data, colWidths=col_widths, hAlign="LEFT")
        n_rows = len(data)
        style_cmds = [
            ("BACKGROUND", (0, 0), (-1, 0), header_bg),
            ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
            ("ALIGN", (0, 0), (-1, 0), "CENTER"),
            ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
            ("FONTSIZE", (0, 0), (-1, 0), font_size),
            ("FONTNAME", (0, 1), (-1, -1), "Helvetica"),
            ("FONTSIZE", (0, 1), (-1, -1), font_size),
            ("TEXTCOLOR", (0, 1), (-1, -1), colors.black),
            ("ALIGN", (0, 1), (-1, -1), "CENTER"),
            ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
            ("LEFTPADDING", (0, 0), (-1, -1), 3),
            ("RIGHTPADDING", (0, 0), (-1, -1), 3),
            ("TOPPADDING", (0, 0), (-1, -1), 2),
            ("BOTTOMPADDING", (0, 0), (-1, -1), 2),
        ]
        if n_rows > 2:
            for r in range(1, n_rows):
                if r % 2 == 1:
                    style_cmds.append(
                        ("BACKGROUND", (0, r), (-1, r), colors.Color(0.96, 0.98, 0.97))
                    )
        tbl.setStyle(TableStyle(style_cmds))
        return tbl

    def fig_to_image(fig, width=6.5, height=2.5):
        img_buffer = BytesIO()
        fig.savefig(img_buffer, format="png", dpi=100, bbox_inches="tight")
        img_buffer.seek(0)
        plt.close(fig)
        return RLImage(img_buffer, width=width * inch, height=height * inch)

    story.append(Paragraph(get_text("pdf_title"), title_style))
    meta_lines = [
        f"Rows: {df.shape[0]}, Columns: {df.shape[1]}",
        f"Numeric columns: {len(numeric_cols)}, Categorical columns: {len(cat_cols)}, Text columns: {len(text_cols)}",
    ]
    for line in meta_lines:
        story.append(Paragraph(line, normal_style))
    story.append(Spacer(1, 0.2 * inch))

    # 1. Numeric distributions
    if numeric_cols:
        story.append(Paragraph(get_text("pdf_section_numdist"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        for col in numeric_cols:
            s = pd.to_numeric(df[col], errors="coerce").dropna()
            if s.empty:
                continue
            stats_dict = {
                "Mean": f"{s.mean():.4f}",
                "Median": f"{s.median():.4f}",
                "Std": f"{s.std():.4f}",
                "Min": f"{s.min():.4f}",
                "Max": f"{s.max():.4f}",
            }
            story.append(Paragraph(f"<b>{col}</b>", h3_style))
            stats_table_data = [["Statistic", "Value"]] + [[k, v] for k, v in stats_dict.items()]
            stats_tbl = make_table(stats_table_data, col_widths=[2.2 * inch, 2.2 * inch], font_size=8)
            if stats_tbl:
                story.append(stats_tbl)
            story.append(Spacer(1, 0.15 * inch))

            fig, axes = plt.subplots(1, 2, figsize=(6.5, 2.2))
            axes[0].hist(s, bins=20, color="#16a34a", edgecolor="black", alpha=0.7)
            axes[0].set_title(f"Histogram - {col}", fontsize=10, fontweight="bold")
            axes[0].set_xlabel("Value")
            axes[0].set_ylabel("Frequency")
            axes[0].grid(alpha=0.3)

            axes[1].boxplot(s, vert=True)
            axes[1].set_title(f"Boxplot - {col}", fontsize=10, fontweight="bold")
            axes[1].set_ylabel("Value")
            axes[1].grid(alpha=0.3, axis="y")

            plt.tight_layout()
            img = fig_to_image(fig, width=6.5, height=2.2)
            story.append(img)
            story.append(Spacer(1, 0.2 * inch))

    # 2. Scatter plots
    if len(numeric_cols) > 1:
        story.append(PageBreak())
        story.append(Paragraph(get_text("pdf_section_scatter"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        pairs_to_plot = min(3, len(numeric_cols) - 1)
        for i in range(pairs_to_plot):
            x_col = numeric_cols[i]
            y_col = numeric_cols[i + 1]
            x = pd.to_numeric(df[x_col], errors="coerce")
            y = pd.to_numeric(df[y_col], errors="coerce")
            mask = x.notna() & y.notna()
            x_clean, y_clean = x[mask], y[mask]
            if len(x_clean) < 2:
                continue

            fig, ax = plt.subplots(figsize=(4.5, 3))
            ax.scatter(x_clean, y_clean, alpha=0.6, color="#10b981", s=40, edgecolors="black", linewidth=0.5)
            z = np.polyfit(x_clean, y_clean, 1)
            p_line = np.poly1d(z)
            ax.plot(x_clean, p_line(x_clean), "r--", alpha=0.8, linewidth=2, label="Trend")
            ax.set_xlabel(x_col, fontsize=9)
            ax.set_ylabel(y_col, fontsize=9)
            ax.set_title(f"Scatter {x_col} vs {y_col}", fontsize=10, fontweight="bold")
            ax.grid(alpha=0.3)
            ax.legend()
            plt.tight_layout()

            img = fig_to_image(fig, width=4.5, height=3)
            story.append(img)
            story.append(Spacer(1, 0.15 * inch))

    # 3. Categorical bar charts
    if cat_cols:
        story.append(PageBreak())
        story.append(Paragraph(get_text("pdf_section_catbar"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        for cat_col in cat_cols[:3]:
            freq = df[cat_col].value_counts().head(10)
            fig, ax = plt.subplots(figsize=(5, 2.5))
            freq.plot(kind="bar", ax=ax, color="#22c55e", edgecolor="black")
            ax.set_title(f"Bar Chart - {cat_col}", fontsize=10, fontweight="bold")
            ax.set_xlabel(cat_col)
            ax.set_ylabel("Frequency")
            ax.tick_params(axis="x", rotation=45)
            ax.grid(alpha=0.3, axis="y")
            plt.tight_layout()

            img = fig_to_image(fig, width=5, height=2.5)
            story.append(img)
            story.append(Spacer(1, 0.2 * inch))

    # 4. Numeric full stats
    if numeric_cols:
        story.append(PageBreak())
        story.append(Paragraph(get_text("pdf_section_numfull"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        for col in numeric_cols:
            s = pd.to_numeric(df[col], errors="coerce").dropna()
            if s.empty:
                continue
            if not s.mode().empty:
                mode_val = f"{s.mode().iloc[0]:.6f}"
            else:
                mode_val = "N/A"
            stats_dict = {
                "Mean": f"{s.mean():.6f}",
                "Median": f"{s.median():.6f}",
                "Mode": mode_val,
                "Std Dev": f"{s.std():.6f}",
                "Variance": f"{s.var():.6f}",
                "Min": f"{s.min():.6f}",
                "Max": f"{s.max():.6f}",
                "Range": f"{(s.max() - s.min()):.6f}",
                "Q1 (25%)": f"{s.quantile(0.25):.6f}",
                "Q3 (75%)": f"{s.quantile(0.75):.6f}",
                "IQR": f"{(s.quantile(0.75) - s.quantile(0.25)):.6f}",
                "Skewness": f"{s.skew():.6f}",
                "Kurtosis": f"{s.kurtosis():.6f}",
            }
            story.append(Paragraph(f"<b>{col}</b>", h3_style))
            table_data = [["Statistic", "Value"]] + [[k, v] for k, v in stats_dict.items()]
            tbl = make_table(table_data, col_widths=[2.5 * inch, 2.5 * inch], font_size=7)
            if tbl:
                story.append(tbl)
            story.append(Spacer(1, 0.15 * inch))

    # 5. Categorical frequency tables
    if cat_cols:
        story.append(PageBreak())
        story.append(Paragraph(get_text("pdf_section_catfreq"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        for col in cat_cols:
            freq = df[col].value_counts(dropna=False).head(15)
            pct = (freq / len(df) * 100).round(2)
            story.append(Paragraph(f"<b>{col}</b> Top 15", h3_style))
            table_data = [["Category", "Count", "Percent"]] + [
                [str(idx), str(int(freq[idx])), f"{pct[idx]:.2f}"] for idx in freq.index
            ]
            tbl = make_table(table_data, col_widths=[2 * inch, 1.5 * inch, 1.5 * inch], font_size=7)
            if tbl:
                story.append(tbl)
            story.append(Spacer(1, 0.15 * inch))

    # 6. Correlation matrix
    if len(numeric_cols) > 1:
        story.append(PageBreak())
        story.append(Paragraph(get_text("pdf_section_corr"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        numeric_df = df[numeric_cols].apply(pd.to_numeric, errors="coerce")
        corr_matrix = numeric_df.corr()
        table_data = [["Variable"] + list(numeric_cols)]
        for var in numeric_cols:
            row = [var]
            for col in numeric_cols:
                r = corr_matrix.loc[var, col]
                row.append(f"{r:.3f}")
            table_data.append(row)
        col_width = 6.5 / (len(numeric_cols) + 1)
        tbl = make_table(
            table_data,
            col_widths=[col_width * inch for _ in range(len(numeric_cols) + 1)],
            font_size=7,
        )
        if tbl:
            story.append(tbl)
        story.append(Spacer(1, 0.2 * inch))

    # 7. Text analysis
    if text_cols:
        story.append(PageBreak())
        story.append(Paragraph(get_text("pdf_section_text"), h2_style))
        story.append(Spacer(1, 0.1 * inch))
        for col in text_cols[:2]:
            story.append(Paragraph(f"<b>{col}</b>", h3_style))
            tokens_series = preprocess_text_series(df[col])
            all_tokens = []
            for token_list in tokens_series:
                all_tokens.extend(token_list)
            if not all_tokens:
                story.append(Paragraph(get_text("pdf_notext"), small_style))
                story.append(Spacer(1, 0.1 * inch))
                continue
            word_freq = Counter(all_tokens).most_common(15)
            table_data = [["Word", "Frequency"]] + [[word, str(count)] for word, count in word_freq]
            tbl = make_table(table_data, col_widths=[3.5 * inch, 2 * inch], font_size=8)
            if tbl:
                story.append(tbl)
            story.append(Spacer(1, 0.2 * inch))

    doc.build(story)
    buffer.seek(0)
    return buffer

def generate_pdf_button(df, numeric_cols, cat_cols, text_cols):
    if st.button(get_text("export_button"), key="btn_export_pdf", type="primary"):
        with st.spinner(get_text("export_desc")):
            time.sleep(0.5)
            pdf_buffer = build_survey_report_pdf(df, numeric_cols, cat_cols, text_cols)
        st.download_button(
            label=get_text("export_button"),
            data=pdf_buffer.getvalue(),
            file_name=get_text("export_filename"),
            mime="application/pdf",
            key="dl_export_pdf",
        )
        st.success("PDF generated successfully!")

# --------------------------- HEADER + HERO ---------------------------
st.markdown(
    f"""
    <div style="
        width:100%;
        padding:0.40rem 0.9rem;
        display:flex;
        justify-content:center;
        background:rgba(240, 253, 250, 0.96);
        box-shadow:0 10px 25px rgba(15, 118, 110, 0.15);
        border:1px solid rgba(45, 212, 191, 0.55);
        margin-bottom:0.9rem;
    ">
      <div style="font-weight:650; color:#047857; font-size:1.1rem;">
        {get_text('title')}
      </div>
    </div>
    """,
    unsafe_allow_html=True,
)

content_font_size = "0.95rem"
st.markdown(
    f"<p style='text-align:center; color:#065f46; font-size:{content_font_size};'>"
    f"{get_text('subtitle')}</p>",
    unsafe_allow_html=True,
)

group_members = [
    {"name": "ADITYA ANGGARA PAMUNGKAS", "sid": "04202400051", "role": "Leader"},
    {"name": "MAULA AQIEL NURI", "sid": "04202400023", "role": "Member"},
    {"name": "SYAFIQ NUR RAMADHAN", "sid": "04202400073", "role": "Member"},
    {"name": "RIFAT FITROTU SALMAN", "sid": "04202400106", "role": "Member"},
]

st.markdown(
    """
    <div class='hero-card' style="margin-top:0.6rem; margin-bottom:0.4rem;">
      <h4 style="margin-top:0; margin-bottom:0.4rem; color:#047857;">
        ðŸ‘¥ Group 5 Class 2
      </h4>
      <ul style="margin:0; padding-left:1.1rem; font-size:0.9rem; color:#065f46;">
    """
    + "\n".join(
        [
            f"<li><b>{m['name']}</b> ({m['sid']}) â€“ {m['role']}</li>"
            for m in group_members
        ]
    )
    + """
      </ul>
    </div>
    """,
    unsafe_allow_html=True,
)

st.markdown("<div class='decorative-divider'></div>", unsafe_allow_html=True)

# --------------------------- UPLOAD & PREVIEW + FILTER ---------------------------
st.markdown("<div class='main-card'>", unsafe_allow_html=True)

st.markdown(
    f"""
    <div class='section-card'>
      <p class='section-title'>{get_text("upload_subheader")}</p>
      <p class='section-subtitle'>{get_text("subtitle")}</p>
    </div>
    """,
    unsafe_allow_html=True,
)

u1, u2, u3 = st.columns([1, 2, 1])
with u2:
    st.markdown("<div class='upload-card'>", unsafe_allow_html=True)
    st.markdown(
        f"<p style='font-weight:600; margin-bottom:0.2rem;'>ðŸ“¤</p>"
        f"<p style='margin-bottom:0.1rem; font-size:{content_font_size};'>"
        f"{get_text('upload_label')}</p>"
        f"<p class='helper-text'>Limit 200MB â€¢ CSV, XLS, XLSX</p>",
        unsafe_allow_html=True,
    )
    uploaded = st.file_uploader(
        "Upload survey file",
        type=["csv", "xls", "xlsx"],
        label_visibility="collapsed",
        accept_multiple_files=False,
    )
    st.markdown("</div>", unsafe_allow_html=True)

df = load_data(uploaded)
if df is None:
    st.info(get_text("no_file"))
    st.markdown("</div>", unsafe_allow_html=True)
    st.stop()

filter_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
filtered_df = df
if filter_cols:
    st.markdown("##### Filter data (optional)")
    fcol = st.selectbox("Filter column", ["(No filter)"] + filter_cols, index=0)
    if fcol != "(No filter)":
        unique_vals = df[fcol].dropna().unique().tolist()
        selected_vals = st.multiselect("Select values", options=unique_vals, default=unique_vals)
        if selected_vals:
            filtered_df = df[df[fcol].isin(selected_vals)]

st.markdown(f"#### {get_text('data_preview')}")
df_preview = filtered_df.head(1000)
st.dataframe(df_preview, height=400)

n_rows, n_cols = filtered_df.shape
n_numeric = filtered_df.select_dtypes(include=[np.number]).shape[1]
n_cat = filtered_df.select_dtypes(exclude=[np.number]).shape[1]
st.markdown(
    f"""
    <div class='section-card'>
      <p class='section-title'>{get_text("data_preview")}</p>
      <p class='section-subtitle'>{get_text("data_preview_subtitle")}</p>
    </div>
    """,
    unsafe_allow_html=True,
)

numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = filtered_df.select_dtypes(exclude=[np.number]).columns.tolist()
text_cols = filtered_df.select_dtypes(include=["object", "string"]).columns.tolist()

# --------------------------- TABS ---------------------------
tab_desc, tab_vis, tab_corr, tab_text = st.tabs(
    [
        get_text("nav_desc"),
        get_text("nav_visual"),
        get_text("nav_corr"),
        get_text("nav_text"),
    ]
)

# Text processing
with tab_text:
    with st.expander(get_text("text_processing_subheader"), expanded=True):
        if not text_cols:
            st.warning(get_text("no_text_columns"))
        else:
            st.markdown(
                get_text("text_columns_detected")
                + f" `{', '.join(text_cols)}`"
            )
            text_col = st.selectbox(
                get_text("select_text_col"),
                options=text_cols,
                help="Select a column for text analysis",
            )
            st.markdown(
                f"<p class='helper-text'>{get_text('text_processing_note')}</p>",
                unsafe_allow_html=True,
            )
            processed = preprocess_text_series(filtered_df[text_col])
            st.markdown(f"**{get_text('sample_tokens')}**")
            st.write(processed.head(5).tolist())
            all_tokens = [t for row in processed for t in row]
            counter = Counter(all_tokens)
            top10 = counter.most_common(10)
            if top10:
                top_df = pd.DataFrame(top10, columns=["word", "count"])
                st.markdown(f"**{get_text('top_words')}**")
                st.table(top_df)

# Descriptive stats
with tab_desc:
    st.markdown(f"### {get_text('stats_subheader')}")
    if not numeric_cols:
        st.warning(get_text("no_numeric_cols"))
    else:
        tab_summ, tab_dist = st.tabs(["Summary & Normality", "Distribution"])
        with tab_summ:
            num_col = st.selectbox(
                get_text("select_numeric_col"),
                options=numeric_cols,
                help="Column for descriptive statistics",
                key="desc_num_col",
            )
            stats_df = descriptive_stats(filtered_df[num_col])
            st.markdown(f"**{get_text('desc_stats')}**")
            st.table(stats_df)
            s_norm = pd.to_numeric(filtered_df[num_col], errors="coerce").dropna()
            if len(s_norm) >= 8:
                stat, p_norm = normaltest(s_norm)
                st.markdown("**Normality test (Dâ€™Agostino-Pearson)**")
                st.write(f"Statistic: {stat:.4f}")
                st.write(f"p-value: {p_norm:.4f}")
                if p_norm < 0.05:
                    st.info("Data deviate significantly from normal distribution (reject H0 at Î± = 0.05).")
                else:
                    st.success("No significant deviation from normal distribution (fail to reject H0 at Î± = 0.05).")
            else:
                st.info("Not enough data points for normality test (need at least 8 non-missing values).")
        with tab_dist:
            num_col2 = st.selectbox(
                "Select column for distribution",
                options=numeric_cols,
                index=0,
                key="desc_num_dist",
            )
            visualize_data(filtered_df, num_col2)
    if not cat_cols:
        st.info(get_text("no_categorical_cols"))
    else:
        cat_col = st.selectbox(
            get_text("select_categorical_col"),
            options=cat_cols,
            help="Column for frequency table",
        )
        freq_df = frequency_tables(filtered_df[cat_col])
        freq_df.columns = [
            get_text("freq_count"),
            get_text("freq_percent"),
        ]
        st.markdown(f"### {get_text('freq_table_subheader')}")
        st.table(freq_df)

# Visualizations
with tab_vis:
    if not numeric_cols:
        st.warning(get_text("no_numeric_cols"))
    else:
        vis_tab1, vis_tab2 = st.tabs(["Histogram / Boxplot", "Scatter & Bar"])
        with vis_tab1:
            num_col = st.selectbox(
                get_text("select_numeric_col"),
                options=numeric_cols,
                help="Column for visualization",
                key="visual_num",
            )
            st.markdown(f"### {get_text('visual_subheader')}")
            visualize_data(filtered_df, num_col)
        with vis_tab2:
            if len(numeric_cols) >= 2:
                c1, c2 = st.columns(2)
                with c1:
                    x_sc = st.selectbox("X variable (numeric)", options=numeric_cols, key="scatter_x")
                with c2:
                    y_sc = st.selectbox("Y variable (numeric)", options=[c for c in numeric_cols if c != x_sc], key="scatter_y")
                s_x = pd.to_numeric(filtered_df[x_sc], errors="coerce")
                s_y = pd.to_numeric(filtered_df[y_sc], errors="coerce")
                mask = s_x.notna() & s_y.notna()
                if mask.sum() > 1:
                    fig, ax = plt.subplots(figsize=(5, 3))
                    ax.scatter(s_x[mask], s_y[mask], alpha=0.6, color="#0f766e")
                    ax.set_xlabel(x_sc)
                    ax.set_ylabel(y_sc)
                    ax.set_title("Scatter plot")
                    st.pyplot(fig)
                else:
                    st.info("Not enough valid data for scatter plot.")
            else:
                st.info("Need at least 2 numeric columns for scatter plot.")

            if cat_cols:
                cat_for_bar = st.selectbox(
                    "Categorical column for bar chart",
                    options=cat_cols,
                    key="bar_cat",
                )
                freq = filtered_df[cat_for_bar].value_counts().head(20)
                fig2, ax2 = plt.subplots(figsize=(6, 3))
                sns.barplot(x=freq.values, y=freq.index, ax=ax2, color="#22c55e")
                ax2.set_xlabel("Count")
                ax2.set_ylabel(cat_for_bar)
                ax2.set_title("Bar chart (top 20)")
                st.pyplot(fig2)
            else:
                st.info("No categorical columns for bar chart.")

# Correlations & tests
with tab_corr:
    st.markdown(f"### {get_text('correlation_subheader')}")
    tab1, tab2, tab3 = st.tabs(
        [
            get_text("pearson_header"),
            get_text("spearman_header"),
            get_text("chi_header"),
        ]
    )
    with tab1:
        if len(numeric_cols) < 2:
            st.info(get_text("not_enough_numeric"))
        else:
            c1p, c2p = st.columns(2)
            with c1p:
                x_num = st.selectbox(
                    get_text("select_x_numeric"),
                    options=numeric_cols,
                    key="pearson_x",
                    help="Independent variable",
                )
            with c2p:
                y_num = st.selectbox(
                    get_text("select_y_numeric"),
                    options=[c for c in numeric_cols if c != x_num],
                    key="pearson_y",
                    help="Dependent variable",
                )
            if x_num and y_num:
                r, p = correlation_analysis(filtered_df, x_num, y_num, method="pearson")
                if np.isnan(r):
                    st.warning(get_text("warning_select_valid"))
                else:
                    st.markdown(f"**{get_text('pearson_result')}**")
                    out = pd.DataFrame(
                        {
                            get_text("corr_coef"): [r],
                            get_text("p_value"): [p],
                        }
                    )
                    st.table(out)
                    st.markdown(
                        f"**{get_text('interpretation')}:** "
                        f"{interpret_strength(r)}"
                    )

    with tab2:
        if len(numeric_cols) < 2:
            st.info(get_text("not_enough_numeric"))
        else:
            c1s, c2s = st.columns(2)
            with c1s:
                x_s = st.selectbox(
                    get_text("select_x_numeric"),
                    options=numeric_cols,
                    key="spearman_x",
                )
            with c2s:
                y_s = st.selectbox(
                    get_text("select_y_numeric"),
                    options=[c for c in numeric_cols if c != x_s],
                    key="spearman_y",
                )
            if x_s and y_s:
                r_s, p_s = correlation_analysis(filtered_df, x_s, y_s, method="spearman")
                if np.isnan(r_s):
                    st.warning(get_text("warning_select_valid"))
                else:
                    st.markdown(f"**{get_text('spearman_result')}**")
                    out_s = pd.DataFrame(
                        {
                            get_text("corr_coef"): [r_s],
                            get_text("p_value"): [p_s],
                        }
                    )
                    st.table(out_s)
                    st.markdown(
                        f"**{get_text('interpretation')}:** "
                        f"{interpret_strength(r_s)}"
                    )

    with tab3:
        chi_df = filtered_df.copy()
        chi_cat_candidates = [
            c for c in chi_df.columns
            if c.startswith("X") or c.startswith("Y") or c == "Responden"
        ]
        for c in chi_cat_candidates:
            chi_df[c] = chi_df[c].astype(str)
        cat_cols_chi = chi_cat_candidates
        if len(cat_cols_chi) < 2:
            st.info(get_text("not_enough_categorical"))
        else:
            c1c, c2c = st.columns(2)
            with c1c:
                x_cat = st.selectbox(
                    get_text("select_x_cat"),
                    options=cat_cols_chi,
                    key="chi_x",
                )
            with c2c:
                y_cat = st.selectbox(
                    get_text("select_y_cat"),
                    options=[c for c in cat_cols_chi if c != x_cat],
                    key="chi_y",
                )
            if x_cat and y_cat:
                table = pd.crosstab(chi_df[x_cat], chi_df[y_cat])
                if table.size == 0:
                    st.warning(get_text("warning_select_valid"))
                else:
                    chi2, p_val, dof_val, expected = chi2_contingency(table)
                    expected_df = pd.DataFrame(expected, index=table.index, columns=table.columns)
                    st.markdown(f"**{get_text('chi_square_result')}**")
                    out_c = pd.DataFrame(
                        {
                            get_text("chi_square_stat"): [chi2],
                            get_text("chi_square_df"): [dof_val],
                            get_text("chi_square_p"): [p_val],
                        }
                    )
                    st.table(out_c)
                    st.markdown("**Observed**")
                    st.dataframe(table, height=200)
                    st.markdown("**Expected**")
                    st.dataframe(expected_df, height=200)
                    st.markdown(f"_{get_text('alpha_note')}_")
                    if p_val < 0.05:
                        st.success(get_text("significant_assoc"))
                    else:
                        st.info(get_text("no_significant_assoc"))

# --------------------------- EXPORT PDF SECTION ---------------------------
st.markdown(f"### {get_text('export_title')}")
st.markdown(get_text("export_desc"))
generate_pdf_button(filtered_df, numeric_cols, cat_cols, text_cols)
